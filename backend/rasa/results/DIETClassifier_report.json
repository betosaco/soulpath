{
  "date": {
    "precision": 1.0,
    "recall": 1.0,
    "f1-score": 1.0,
    "support": 102,
    "confused_with": {}
  },
  "name": {
    "precision": 1.0,
    "recall": 1.0,
    "f1-score": 1.0,
    "support": 9,
    "confused_with": {}
  },
  "sign": {
    "precision": 1.0,
    "recall": 1.0,
    "f1-score": 1.0,
    "support": 25,
    "confused_with": {}
  },
  "email_address": {
    "precision": 1.0,
    "recall": 1.0,
    "f1-score": 1.0,
    "support": 2,
    "confused_with": {}
  },
  "language_preference": {
    "precision": 1.0,
    "recall": 1.0,
    "f1-score": 1.0,
    "support": 2,
    "confused_with": {}
  },
  "package_name": {
    "precision": 1.0,
    "recall": 0.8181818181818182,
    "f1-score": 0.9,
    "support": 33,
    "confused_with": {
      "package_id": 6
    }
  },
  "phone_number": {
    "precision": 1.0,
    "recall": 1.0,
    "f1-score": 1.0,
    "support": 2,
    "confused_with": {}
  },
  "question_text": {
    "precision": 1.0,
    "recall": 1.0,
    "f1-score": 1.0,
    "support": 7,
    "confused_with": {}
  },
  "person_name": {
    "precision": 1.0,
    "recall": 1.0,
    "f1-score": 1.0,
    "support": 6,
    "confused_with": {}
  },
  "package_id": {
    "precision": 0.875,
    "recall": 1.0,
    "f1-score": 0.9333333333333333,
    "support": 42,
    "confused_with": {}
  },
  "birth_place": {
    "precision": 1.0,
    "recall": 1.0,
    "f1-score": 1.0,
    "support": 6,
    "confused_with": {}
  },
  "birth_date": {
    "precision": 1.0,
    "recall": 1.0,
    "f1-score": 1.0,
    "support": 6,
    "confused_with": {}
  },
  "birth_time": {
    "precision": 1.0,
    "recall": 1.0,
    "f1-score": 1.0,
    "support": 4,
    "confused_with": {}
  },
  "micro avg": {
    "precision": 0.975609756097561,
    "recall": 0.975609756097561,
    "f1-score": 0.975609756097561,
    "support": 246
  },
  "macro avg": {
    "precision": 0.9903846153846154,
    "recall": 0.986013986013986,
    "f1-score": 0.9871794871794872,
    "support": 246
  },
  "weighted avg": {
    "precision": 0.9786585365853658,
    "recall": 0.975609756097561,
    "f1-score": 0.9752032520325202,
    "support": 246
  },
  "accuracy": 0.9973214285714286
}